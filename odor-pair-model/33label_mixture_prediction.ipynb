{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f19f97ec-335b-4b32-bcca-932bf10732a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, GINConv, NNConv, global_add_pool, global_mean_pool, aggr\n",
    "from pairing.data import PairData, to_torch, Dataset\n",
    "import pandas as pd\n",
    "from itertools import combinations, product\n",
    "import os\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_convs, num_linear, embedding_size, aggr_steps, architecture):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.layers = []\n",
    "        self.task = \"graph\"\n",
    "\n",
    "        self.pad = torch.nn.ZeroPad2d(\n",
    "            (0, embedding_size - Dataset.num_node_features(), 0, 0))\n",
    "\n",
    "        self.gcn = self.make_conv(architecture, num_linear, embedding_size)\n",
    "        self.gcn.to(device)\n",
    "        self.num_convs = num_convs\n",
    "\n",
    "        self.architecture = architecture\n",
    "\n",
    "        self.aggr_steps = aggr_steps\n",
    "        self.readout = aggr.Set2Set(embedding_size, aggr_steps)\n",
    "        self.readout.to(device)\n",
    "\n",
    "        self.post_mp = make_sequential(num_linear,\n",
    "                                       2 * embedding_size,\n",
    "                                       embedding_size,\n",
    "                                       is_last=True)\n",
    "        self.post_mp.to(device)\n",
    "\n",
    "    def make_conv(self, architecture, num_linear, embedding_size):\n",
    "        if architecture == \"GCN\":\n",
    "            return GCNConv(embedding_size, embedding_size)\n",
    "        elif architecture == \"GIN\":\n",
    "            return GINConv(make_sequential(num_linear, embedding_size, embedding_size))\n",
    "        elif architecture == \"NNConv\":\n",
    "            mpfn = make_sequential(1, Dataset.num_edge_features(), embedding_size**2)\n",
    "            return NNConv(embedding_size, embedding_size, mpfn)\n",
    "        else:\n",
    "            raise KeyError(f\"Received invalid architecture = {architecture}.\")\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch_index):\n",
    "        x = self.pad(x)\n",
    "        for _ in range(self.num_convs):\n",
    "            if self.architecture == \"NNConv\":\n",
    "                x = self.gcn(x, edge_index, edge_attr)\n",
    "            else:\n",
    "                x = self.gcn(x, edge_index)\n",
    "\n",
    "        pooled = torch.cat([global_add_pool(x, batch_index), global_mean_pool(x, batch_index)], dim=1)\n",
    "        if self.aggr_steps > 0:\n",
    "            pooled = self.readout(x, index=batch_index)\n",
    "        return self.post_mp(pooled)\n",
    "\n",
    "\n",
    "class MixturePredictor(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_convs, num_linear, embedding_size, aggr_steps, architecture):\n",
    "        super(MixturePredictor, self).__init__()\n",
    "\n",
    "        self.gcn = GCN(num_convs, num_linear, embedding_size, aggr_steps, architecture)\n",
    "        self.out = make_sequential(num_linear,\n",
    "                                   2 * embedding_size,\n",
    "                                   33,  # Dataset.num_classes(),\n",
    "                                   is_last=True)\n",
    "\n",
    "    def forward(self, x_s, edge_index_s, edge_attr_s, x_s_batch, x_t, edge_index_t,\n",
    "                edge_attr_t, x_t_batch, y, *args, **kwargs):\n",
    "        emb_s = self.gcn(x_s, edge_index_s, edge_attr_s, x_s_batch)\n",
    "        emb_t = self.gcn(x_t, edge_index_t, edge_attr_t, x_t_batch)\n",
    "\n",
    "        embedding = torch.cat([emb_s, emb_t], dim=1)\n",
    "        return self.out(embedding)\n",
    "\n",
    "def make_sequential(num_layers, input_dim, output_dim, is_last=False):\n",
    "    layers = []\n",
    "    layers.append(\n",
    "        torch.nn.Sequential(torch.nn.Linear(input_dim, output_dim),\n",
    "                            torch.nn.ReLU(), torch.nn.Dropout(p=0.5)))\n",
    "    while len(layers) < num_layers:\n",
    "        layers.append(\n",
    "            torch.nn.Sequential(torch.nn.Linear(output_dim, output_dim),\n",
    "                                torch.nn.ReLU(), torch.nn.Dropout(p=0.5)))\n",
    "\n",
    "    if is_last:\n",
    "        if num_layers == 1:\n",
    "            layers[-1] = torch.nn.Sequential(\n",
    "                torch.nn.Linear(input_dim, output_dim))\n",
    "        else:\n",
    "            layers[-1] = torch.nn.Sequential(\n",
    "                torch.nn.Linear(output_dim, output_dim))\n",
    "\n",
    "    return torch.nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Load the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = \"model_33.pt\"  # Path to your trained model\n",
    "model = torch.load(model_path, map_location=device)\n",
    "model.eval()\n",
    "\n",
    "# Load the CIDs to SMILES mapping\n",
    "cids_df = pd.read_csv('CID_SMILES.csv')\n",
    "cid_to_smiles = dict(zip(cids_df['CID'], cids_df['Canonical SMILES']))\n",
    "\n",
    "# Load the mixtures\n",
    "mixtures_df = pd.read_csv('Mixure_Definitions_augmented_dataset.csv')\n",
    "\n",
    "# Function to create PairData instances from SMILES pairs without notes\n",
    "def create_pair_data_without_notes(smiles1, smiles2, num_classes):\n",
    "    graph1 = to_torch(smiles1)\n",
    "    graph2 = to_torch(smiles2)\n",
    "    \n",
    "    # Create a dummy target tensor\n",
    "    y = torch.zeros(num_classes)\n",
    "    \n",
    "    return PairData(\n",
    "        x_s=graph1['node_feat'].float(),\n",
    "        edge_attr_s=graph1['edge_feat'].float(),\n",
    "        edge_index_s=graph1['edge_index'],\n",
    "        smiles_s=smiles1,\n",
    "        x_t=graph2['node_feat'].float(),\n",
    "        edge_attr_t=graph2['edge_feat'].float(),\n",
    "        edge_index_t=graph2['edge_index'],\n",
    "        smiles_t=smiles2,\n",
    "        y=y.float()\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def predict_for_mixture(cid_list, num_classes):\n",
    "    smiles_list = [cid_to_smiles[int(cid)] for cid in cid_list if int(cid) in cid_to_smiles]\n",
    "    if len(smiles_list) == 1:\n",
    "        pair_combinations = product(smiles_list, repeat=2)\n",
    "    else:\n",
    "        pair_combinations = combinations(smiles_list, 2)\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for smiles1, smiles2 in pair_combinations:\n",
    "        pair_data = create_pair_data_without_notes(smiles1, smiles2, num_classes)\n",
    "        loader = DataLoader([pair_data], batch_size=1, follow_batch=['x_s', 'x_t'])\n",
    "        \n",
    "        for batch_data in loader:\n",
    "            batch_data.to(device)\n",
    "            with torch.no_grad():\n",
    "                logits = model(**batch_data.to_dict())\n",
    "                sigmoid = torch.nn.Sigmoid()\n",
    "                probs = sigmoid(logits)\n",
    "                predictions.append(probs.cpu().numpy())\n",
    "                \n",
    "    \n",
    "    if predictions:\n",
    "        predictions_array = np.vstack(predictions)\n",
    "        return np.mean(predictions_array, axis=0)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    num_classes = 33  # this must match the number that model was trained with\n",
    "    results = []\n",
    "\n",
    "    for idx, row in mixtures_df.iterrows():\n",
    "        dataset = row['Dataset']\n",
    "        mixture_label = row['Mixture Label']\n",
    "        cid_list = [row[f'CID_{i+1}'] for i in range(10) if not pd.isna(row[f'CID_{i+1}'])]\n",
    "\n",
    "        avg_prediction = predict_for_mixture(cid_list, num_classes)\n",
    "        \n",
    "        if avg_prediction is not None:\n",
    "            results.append({\n",
    "                'Dataset': dataset,\n",
    "                'Mixture Label': mixture_label,\n",
    "                'Average Prediction': avg_prediction\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(inetrmediate_outpt, index=False)\n",
    "\n",
    "inetrmediate_outpt = 'mixture_predictions_33.csv'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "predictions_df = pd.read_csv(inetrmediate_outpt)\n",
    "\n",
    "# Function to safely evaluate the string representation of arrays\n",
    "def safe_eval(array_str):\n",
    "    try:\n",
    "        # Use regex to clean the string and make it a valid Python list\n",
    "        array_str = re.sub(r'(\\s+)', ',', array_str)  # Replace any whitespace with a comma\n",
    "        array_str = re.sub(r'([0-9])\\s+(?=[0-9])', r'\\1,', array_str)  # Replace space between numbers with a comma\n",
    "        return np.array(ast.literal_eval(array_str))\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing array: {e}\")\n",
    "        return np.array([])\n",
    "\n",
    "average_predictions = predictions_df['Average Prediction'].apply(safe_eval).values\n",
    "\n",
    "if len(average_predictions) == 0 or all(arr.size == 0 for arr in average_predictions):\n",
    "    print(\"No valid predictions found in the 'Average Prediction' column.\")\n",
    "else:\n",
    "    average_predictions = np.vstack(average_predictions)\n",
    "\n",
    "    num_predictions = average_predictions.shape[1]\n",
    "    prediction_columns = [f'Prediction_{i+1}' for i in range(num_predictions)]\n",
    "\n",
    "    predictions_array_df = pd.DataFrame(average_predictions, columns=prediction_columns)\n",
    "\n",
    "    # Combine the original data with the new prediction columns\n",
    "    combined_df = pd.concat([predictions_df[['Dataset', 'Mixture Label']], predictions_array_df], axis=1)\n",
    "\n",
    "    # Save the updated dataframe to a new CSV file\n",
    "    output_file2 = 'predictions_separated_mean_33_Augmentation_Dataset.csv'\n",
    "    combined_df.to_csv(output_file2, index=False)\n",
    "\n",
    "    print(f\"Predictions separated into columns saved to {output_file}\")\n",
    "    print(combined_df.head())  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpom1",
   "language": "python",
   "name": "openpom1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
